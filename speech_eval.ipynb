{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import os, subprocess\n",
    "\n",
    "def replace_audio_in_video(video_path, audio_path, output_path):\n",
    "    \"\"\"\n",
    "    批量替换MP4文件的音频\n",
    "    video_folder: MP4文件所在文件夹\n",
    "    audio_folder: WAV文件所在文件夹\n",
    "    output_folder: 输出文件保存文件夹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-y',\n",
    "            '-i', video_path,           # 输入视频文件\n",
    "            '-i', audio_path,          # 输入音频文件\n",
    "            '-c:v', 'copy',            # 直接复制视频流\n",
    "            '-c:a', 'aac',             # 编码音频为AAC\n",
    "            '-map', '0:v:0',           # 选择视频流的第0个视频轨道\n",
    "            '-map', '1:a:0',           # 选择音频流的第0个音频轨道\n",
    "            '-shortest',               # 以最短的流长度为准\n",
    "            output_path\n",
    "        ]\n",
    "            \n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理失败: {output_path}, 错误: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "model = 'vasflow'\n",
    "group = '10'\n",
    "epoch = '0129'\n",
    "\n",
    "# files = glob(f\"./log/2025_05_13-*-vaflow_sda_dit_noise_text_mel_10l_cc_first10/val/video/epoch_{epoch}*/audio_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_18-*-vaflow_sda_dit_noise_text_clip_mel_10l_cn_first10/val/video/epoch_{epoch}*/audio_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_27-19_*-vaflow_sda_dit_noise_text_mel_infer_vas_cfg2/predict/video/audio_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_23-20_*-vaflow_sda_dit_noise_text_mel_infer_va_cfg0/predict/video/audio_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_26-16*_dit_noise_text_clip_mel_infer/predict/video/audio_*_00.wav\")\n",
    "\n",
    "for audio_file in tqdm(files):\n",
    "    name = audio_file.split('/')[-1][6:-7]\n",
    "    target_file = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/{model}/{group}/{name}.wav\"\n",
    "    shutil.copy(audio_file, target_file)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094f6a4",
   "metadata": {},
   "source": [
    "# Replace Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ade44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for file in os.listdir('/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vasflow/10')[5400:5500]:\n",
    "#     name = file[:-4]\n",
    "#     video_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/dataset/test/10/{name}.mp4\"  # Path to the input MP4 video\n",
    "#     audio_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vasflow/10/{file}\"    # Path to the new audio (can be MP3, WAV, etc.)\n",
    "#     output_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vasflow/video/{name}.mp4\" # Path for the output video\n",
    "    \n",
    "#     replace_audio_in_video(video_path, audio_path, output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name = 'ruK8QzIWrSY_000080'\n",
    "# for baseline in ['difffoley', 'seeing', 'Frieren', 'stablev2a_', 'tiva', 'test', 'vaura', 'specvqgan', 'im2wav', 'vab', 'v2a-mapper']:\n",
    "#     video_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/dataset/test/10/{name}.mp4\"  # Path to the input MP4 video\n",
    "#     audio_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/{baseline}/10/{name}.wav\"    # Path to the new audio (can be MP3, WAV, etc.)\n",
    "#     output_path = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/demo/{baseline}_{name}.mp4\" # Path for the output video\n",
    "#     try:\n",
    "#         replace_audio_in_video(video_path, audio_path, output_path)\n",
    "#     except:\n",
    "#         print(baseline, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd50575",
   "metadata": {},
   "source": [
    "# SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86398b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3491/3491 [00:00<00:00, 575042.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 3291, 200, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "model = 'vasflow'\n",
    "epoch = '0129'\n",
    "# files = glob(\"/home/chengxin/chengxin/vasflow/log/2025_05_07-13_*/predict/video/audio_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_18-*-vaflow_sda_dit_noise_text_clip_mel_10l_cn_first10/val/video/epoch_{epoch}*/speech_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_07_04-*-vaflow_sda_dit_noise_text_mel_infer_chem_grid/predict/video/speech_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_07_04-19_*-vaflow_sda_dit_noise_text_mel_infer_chem/predict/video/speech_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_22-14_*-vaflow_sda_dit_noise_text_mel_infer_va/predict/video/speech_*_00.wav\")\n",
    "\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_26-14_*_dit_noise_text_mel_infer/predict/video/speech_*_00.wav\")\n",
    "\n",
    "ljfiles = []\n",
    "gridfiles = []\n",
    "chemfiles = []\n",
    "lrsfiles = []\n",
    "for audio_file in tqdm(files):\n",
    "    name = audio_file.split('/')[-1][7:-7]\n",
    "    if name.startswith('LJ00'):\n",
    "        ljfiles.append(audio_file)\n",
    "    elif bool(re.match(r'^s(?:0[0-9]|[12][0-9]|3[0-5])', name)):\n",
    "        gridfiles.append(audio_file)\n",
    "    elif name.startswith('chem'):\n",
    "        chemfiles.append(audio_file)\n",
    "    else:\n",
    "        lrsfiles.append(audio_file)\n",
    "    # target_file = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/{model}/{group}/{name}.wav\"\n",
    "    # shutil.copy(audio_file, target_file)\n",
    "\n",
    "len(ljfiles), len(gridfiles), len(chemfiles), len(lrsfiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d62350",
   "metadata": {},
   "source": [
    "# 1. wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33334a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/wav.scp\n"
     ]
    }
   ],
   "source": [
    "visualtts_dataset = 'GRID'\n",
    "meta_file_dir = f\"/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}\"\n",
    "gen_file_paths = gridfiles\n",
    "output_scp_path = f\"{meta_file_dir}/results/{model}/wer/wav.scp\"\n",
    "\n",
    "\n",
    "with open(output_scp_path, \"w\") as scp_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "\n",
    "        name = f\"visual_tts_{file_id}_sample{sample_id}\"\n",
    "        gen_path = file_path\n",
    "        scp_file.write(f\"{name} {gen_path}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_scp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1caed",
   "metadata": {},
   "source": [
    "# 2. utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a80f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/utt2spk\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/utt2spk\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as utt_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        spk_id = '_'.join(file_id.split(\"_\")[:-1])\n",
    "\n",
    "\n",
    "        name = f\"{file_id}\"\n",
    "        gt_path = f\"{meta_file_dir}/speakers/{file_id}.wav\" # LJSpeech\n",
    "        gt_path = f\"{meta_file_dir}/speakers/{spk_id}/{file_id}.wav\"  # GRID LRS CHEM\n",
    "        utt_file.write(f\"{name} {gt_path}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccb0c3",
   "metadata": {},
   "source": [
    "# 3. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c432253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/text\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/text\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as txt_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        spk_id = '_'.join(file_id.split(\"_\")[:-1])\n",
    "        \n",
    "\n",
    "        name = f\"{file_id}\"\n",
    "        # gt_transcript_path = f\"{meta_file_dir}/speakers/{file_id}.lab\" # LJSpeech\n",
    "        gt_transcript_path = f\"{meta_file_dir}/speakers/{spk_id}/{file_id}.lab\" # GRID LRS CHEM\n",
    "        with open(gt_transcript_path, \"r\") as lab_file:\n",
    "            gt_transcript = lab_file.read().strip()\n",
    "        txt_file.write(f\"{name} {gt_transcript}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5dd5c",
   "metadata": {},
   "source": [
    "# key_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06835483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/key_file\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/key_file\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as key_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        \n",
    "        name = f\"visual_tts_{file_id}\"\n",
    "        key_file.write(f\"{name}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48695190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:16<00:00, 11.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import subprocess\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_dir = f'/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}/results/{model}/data'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for file_path in tqdm(gen_file_paths[:200]):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "    sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "\n",
    "    name = f\"{file_id}_sample{sample_id}\"\n",
    "    shutil.copy(file_path, f\"{save_dir}/{name}.wav\")\n",
    "\n",
    "    if visualtts_dataset == 'Chem':\n",
    "        file_id = file_id[8:]\n",
    "        gt_video_path = f\"{meta_file_dir}/sentence_video_25fps/{file_id}.mp4\"  # Chem\n",
    "    elif visualtts_dataset == 'GRID':\n",
    "        spk = file_id.split(\"_\")[0]\n",
    "        gt_video_path = f\"{meta_file_dir}/videos_25fps_mp4/{spk}/{file_id}.mp4\"  # Chem\n",
    "    elif visualtts_dataset == 'LRS2':\n",
    "        spk = \"_\".join(file_id.split(\"_\")[:2])\n",
    "        gt_video_path = f\"{meta_file_dir}/video_25fps/{spk}/{file_id}.mp4\"  # Chem    shutil.copy(gt_video_path, f\"{save_dir}/{name}.mp4\")\n",
    "    replace_audio_in_video(gt_video_path, f\"{save_dir}/{name}.wav\", f\"{save_dir}/{name}.mp4\")\n",
    "    # print(f\"{save_dir}/{name}.wav\", f\"{save_dir}/{name}.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf859c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualtts_dataset = 'GRID'\n",
    "# meta_file_dir = f\"/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}\"\n",
    "# file_name = 's28_pris7n_sample0'\n",
    "# for baseline in ['HPMDubbing_randomref', 'emodubber_randomref', 'gt_vocoder', 'style_randomref', 'dsu', 'vasflow']:\n",
    "#     if visualtts_dataset == 'Chem':\n",
    "#         file_id = '_'.join(file_name.split(\"_\")[2:-1])\n",
    "#         gt_video_path = f\"{meta_file_dir}/sentence_video_25fps/{file_id}.mp4\" \n",
    "#         wav_path =  f'/home/chengxin/chengxin/Dataset_Sound/Chem/results/{baseline}/data/{file_name}.wav'\n",
    "#         target_path = f'/home/chengxin/chengxin/Dataset_Sound/Chem/results/demo/{baseline}_{file_name}.mp4'\n",
    "#         replace_audio_in_video(gt_video_path, wav_path, target_path)\n",
    "#     if visualtts_dataset == 'GRID':\n",
    "#         file_id = '_'.join(file_name.split(\"_\")[:-1])\n",
    "#         spk = file_id.split(\"_\")[0]\n",
    "#         gt_video_path = f\"{meta_file_dir}/videos_25fps_mp4/{spk}/{file_id}.mp4\"  # Chem\n",
    "#         wav_path =  f'/home/chengxin/chengxin/Dataset_Sound/GRID/results/{baseline}/data/{file_name}.wav'\n",
    "#         target_path = f'/home/chengxin/chengxin/Dataset_Sound/GRID/results/demo/{baseline}_{file_name}.mp4'\n",
    "#         replace_audio_in_video(gt_video_path, wav_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b162ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32017205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bf9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df181f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8389e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
